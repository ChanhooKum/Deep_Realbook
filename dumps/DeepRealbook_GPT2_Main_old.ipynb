{"cells":[{"cell_type":"markdown","source":["# Mount and import"],"metadata":{"id":"jqylZSYv6E-c"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28128,"status":"ok","timestamp":1709014491204,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"},"user_tz":-540},"id":"NUUtUN2t7k3e","outputId":"696aeb5f-fefe-4bd7-888b-22f2b81704c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'config' from '/content/drive/My Drive/Colab Notebooks/MARG/Deep Realbook/utils/config.py'>"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Base folder path\n","data_folder = '/content/drive/My Drive/Colab Notebooks/MARG/Deep Realbook/data/'\n","models_folder = '/content/drive/My Drive/Colab Notebooks/MARG/Deep Realbook/models/'\n","utils_folder = '/content/drive/My Drive/Colab Notebooks/MARG/Deep Realbook/utils/'\n","\n","import sys\n","sys.path.append(utils_folder)\n","\n","import importlib\n","import utils, config\n","\n","importlib.reload(utils)  # Reload the module after making changes\n","importlib.reload(config)  # Reload the module after making changes"]},{"cell_type":"markdown","source":["# Preprocess"],"metadata":{"id":"wSU4w5k-5mmX"}},{"cell_type":"markdown","metadata":{"id":"TQILwucvjdJR"},"source":["## Chord sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SEPvaXbWZXFp"},"outputs":[],"source":["from utils import extract_chords_from_json\n","\n","file_name = 'playlist.json'\n","json_file_path = data_folder + file_name\n","chord_sequences = extract_chords_from_json(json_file_path)\n","\n","# Print the chord sequences\n","for song, chords in chord_sequences.items():\n","    print(f\"{song}: {chords}\")\n"]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","\n","# Specific tension pairs to compare\n","specific_tension_pairs = [\n","    ('', '-#5'),\n","    ('9b5', '9#5'),\n","    ('7#11', '7b9b5'),\n","    ('-b6', '^7'),\n","    ('-7', '6'),\n","    ('7b9#9', '13b9'),\n","    ('13sus', '-11'),\n","    ('69', '9sus'),\n","    ('7b9sus', '-69'),\n","    ('13', '^13'),\n","    ('sus', '2'),\n","    ('-6', 'h7'),\n","    ('7b9#5', 'h9')\n","]\n","\n","# Function to extract tensions from a chord\n","def extract_tensions(chord):\n","    regex = r\"[^A-G][b#]?\\d*\"\n","    return re.findall(regex, chord)\n","\n","# Function to extract and count tensions from all chord sequences\n","def count_tensions_in_chords(chord_sequences):\n","    tensions = []\n","    for sequence in chord_sequences.values():\n","        for chord in sequence:\n","            if chord != '|':  # Exclude bar symbols\n","                tensions.extend(extract_tensions(chord))\n","    return Counter(tensions)\n","\n","# Counting tensions in all sequences\n","all_tensions_count = count_tensions_in_chords(chord_sequences)\n","\n","# Function to compare tension frequencies for the given pairs\n","def compare_tension_frequencies(tension_count, pairs):\n","    comparisons = {}\n","    for pair in pairs:\n","        tension1, tension2 = pair\n","        count1 = tension_count.get(tension1, 0)\n","        count2 = tension_count.get(tension2, 0)\n","        comparisons[pair] = (count1, count2)\n","    return comparisons\n","\n","# Compare frequencies for the specified tension pairs\n","tension_pair_comparisons = compare_tension_frequencies(all_tensions_count, specific_tension_pairs)\n","\n","# Display the results\n","tension_pair_comparisons\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWKz9iliXgx3","executionInfo":{"status":"ok","timestamp":1708414601027,"user_tz":-540,"elapsed":722,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"954119e7-4799-4a9e-f1d3-d62ddf338138"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('', '-#5'): (0, 15),\n"," ('9b5', '9#5'): (14, 17),\n"," ('7#11', '7b9b5'): (343, 0),\n"," ('-b6', '^7'): (58, 9674),\n"," ('-7', '6'): (17237, 2023),\n"," ('7b9#9', '13b9'): (0, 0),\n"," ('13sus', '-11'): (0, 318),\n"," ('69', '9sus'): (66, 0),\n"," ('7b9sus', '-69'): (0, 25),\n"," ('13', '^13'): (297, 3),\n"," ('sus', '2'): (0, 0),\n"," ('-6', 'h7'): (1019, 2560),\n"," ('7b9#5', 'h9'): (0, 7)}"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"muZlh6HXjjjV"},"source":["## Vector representations"]},{"cell_type":"code","source":["from utils import create_vector_representation\n","\n","vector_representations = create_vector_representation(chord_sequences)\n","\n","for song, vectors in vector_representations.items():\n","    print(f\"{song}: {vectors}\")"],"metadata":{"id":"wv2U3kg_JKKI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7TtGokNmjoZ1"},"source":["## Circular representations"]},{"cell_type":"code","source":["from utils import generate_sequence_tokens\n","\n","# Assuming 'songs' contains your original song data\n","circular_representations = generate_sequence_tokens(vector_representations)\n","\n","# Example of how to view the new sequences\n","for song, circulars in circular_representations.items():\n","    print(f\"{song}: {circulars}\")"],"metadata":{"id":"Nni7h0Ip1df2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLiCCrq7judr"},"source":["## Mapped results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708069287373,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"},"user_tz":-540},"id":"8s5zxBRB-Q7i","outputId":"51a7dd8c-a27d-4e24-f213-da684d861630"},"outputs":[{"output_type":"stream","name":"stdout","text":["First few mapped results:\n","('C', 'C', ['A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'D', 'A', 'A', 'D'])\n","('C', 'C7#11', ['A', 'A', 'A', 'D', 'A', 'C', 'D', 'A', 'A', 'C', 'A', 'D'])\n","('C', 'C-7', ['A', 'A', 'C', 'A', 'D', 'A', 'A', 'C', 'B', 'A', 'A', 'D'])\n","('C', 'C13#9', ['A', 'A', 'C', 'D', 'A', 'A', 'D', 'A', 'C', 'C', 'A', 'D'])\n","('C', 'C69', ['A', 'A', 'D', 'A', 'C', 'A', 'A', 'D', 'A', 'C', 'A', 'D'])\n"]}],"source":["from config import tension_intervals_reduced\n","from utils import chord_to_vector, map_vectors_to_categories, get_lexicographically_smallest_rotation\n","\n","from itertools import product\n","\n","# Define the roots and tensions\n","first_root = 'C'\n","other_roots = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'Gb', 'G', 'Ab', 'A', 'Bb', 'B']\n","tensions = list(tension_intervals_reduced.keys())\n","\n","# Generate all combinations for chord-to-chord mapping with first root as 'C'\n","chord_to_chord_pairs = [(first_root + tension1, root2 + tension2) for tension1, root2, tension2 in product(tensions, other_roots, tensions)]\n","\n","# Generate pairs involving 'NC', using 'C' as the root\n","nc_pairs = [(first_root + tension, 'NC') for tension in tensions] + \\\n","           [('NC', first_root + tension) for tension in tensions] + \\\n","           [('NC', 'NC')]\n","\n","# Combine both sets of pairs\n","all_chord_pairs = chord_to_chord_pairs + nc_pairs\n","\n","# Process each chord pair\n","mapped_results = []\n","for first_chord, next_chord in all_chord_pairs:\n","    vector1 = chord_to_vector(first_chord)\n","    vector2 = chord_to_vector(next_chord)\n","    categories = map_vectors_to_categories(vector1, vector2)\n","    smallest_rotation = get_lexicographically_smallest_rotation(categories)\n","    mapped_results.append((first_chord, next_chord, smallest_rotation))\n","\n","# Print some examples from the results\n","print(\"First few mapped results:\")\n","for example in mapped_results[:5]:\n","    print(example)\n"]},{"cell_type":"markdown","metadata":{"id":"4BEu3pvvjypB"},"source":["# Save and load preprocessed data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNZIFRJs2N4n"},"outputs":[],"source":["import json\n","\n","# Save as JSON\n","with open(data_folder + 'chord_sequences.json', 'w') as file:\n","    json.dump(chord_sequences, file)\n","\n","with open(data_folder + 'vector_representations.json', 'w') as file:\n","    json.dump(vector_representations, file)\n","\n","with open(data_folder + 'circular_representations.json', 'w') as file:\n","    json.dump(circular_representations, file)\n","\n","with open(data_folder + 'mapped_results.json', 'w') as file:\n","    json.dump(mapped_results, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqVreLp02O-i"},"outputs":[],"source":["import json\n","\n","# Load the dictionary\n","with open(data_folder + 'chord_sequences.json', 'r') as file:\n","    chord_sequences = json.load(file)\n","\n","with open(data_folder + 'vector_representations.json', 'r') as file:\n","    vector_representations = json.load(file)\n","\n","with open(data_folder + 'circular_representations.json', 'r') as file:\n","    circular_representations = json.load(file)\n","\n","with open(data_folder + 'mapped_results.json', 'r') as file:\n","    mapped_results = json.load(file)"]},{"cell_type":"markdown","metadata":{"id":"8WG5zkUIj-U3"},"source":["# GPT2 fine_tune"]},{"cell_type":"markdown","source":["## Import and device"],"metadata":{"id":"1j92erDv5yMj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iqb5x08cCqz_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709014513244,"user_tz":-540,"elapsed":16178,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"905e2fd9-b46f-4e40-8086-9d615d5b448c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m276.5/280.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.27.2\n","Using device: cuda\n"]}],"source":["!pip install accelerate -U\n","\n","import torch\n","from tokenizers import Tokenizer, models, trainers\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, pipeline\n","\n","# Check if CUDA is available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","source":["representation_to_use = chord_sequences"],"metadata":{"id":"Zsanpbv8IuIn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenizer"],"metadata":{"id":"SXVArsIj5Myg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISmLVh13iJD5"},"outputs":[],"source":["# Extract unique sequences\n","unique_sequences = set()\n","\n","for sequences in representation_to_use.values():\n","    unique_sequences.update(sequences)\n","\n","# Write the sequences to a file\n","with open(\"unique_sequences.txt\", \"w\") as file:\n","    for sequence in unique_sequences:\n","        file.write(sequence + \"\\n\")"]},{"cell_type":"code","source":["# Initialize a tokenizer with BPE\n","tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n","trainer = trainers.BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n","\n","# Train the tokenizer\n","tokenizer.train([\"unique_sequences.txt\"], trainer)\n","\n","# Save the tokenizer\n","tokenizer.save(models_folder + \"custom_tokenizer\")"],"metadata":{"id":"Gt59gTckWWyl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"NmLWOiza5SGg"}},{"cell_type":"code","source":["from config import validation_set\n","\n","# Split data into training and validation\n","train_sequences = {k: v for k, v in representation_to_use.items() if k not in validation_set}\n","validation_sequences = {k: representation_to_use[k] for k in validation_set}\n","\n","# Write the training sequences to a file\n","with open(\"training_sequences.txt\", \"w\") as file:\n","    for sequences in train_sequences.values():\n","        file.write(\" \".join(sequences) + \"\\n\")\n","\n","# Write the validation sequences to a file\n","with open(\"validation_sequences.txt\", \"w\") as file:\n","    for sequences in validation_sequences.values():\n","        file.write(\" \".join(sequences) + \"\\n\")"],"metadata":{"id":"8CxNxeb9FyiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load your custom tokenizer\n","tokenizer = PreTrainedTokenizerFast(tokenizer_file=models_folder + \"custom_tokenizer\")\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","# Load GPT-2 model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Prepare datasets for training and validation\n","train_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"training_sequences.txt\",\n","    block_size=512\n",")\n","validation_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"validation_sequences.txt\",\n","    block_size=512\n",")\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=False\n",")\n","\n","# Update TrainingArguments to include evaluation during training\n","training_args = TrainingArguments(\n","    output_dir=models_folder + \"gpt2-text-reps_custom_token\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=100,\n","    per_device_train_batch_size=4,\n","    save_steps=1_000,\n","    save_total_limit=3,\n","    evaluation_strategy=\"epoch\",  # Evaluate each epoch\n",")\n","\n","# Instantiate Trainer with validation dataset\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276,"referenced_widgets":["34b34848440a4b15aac63aab6b0e8aab","366a2eed12964e68b42afa9670b62a65","056cbf7417e640f4bcded50d0a217c03","e3c61bca26484305baffe5e0e15fa7a5","6fba82c7940d4e8ea9f7512553b82858","32c4e9adcab14b25b0ef3fa5ca7fb87b","ff901cacea74432296ec0d8ca33ec64e","4a015ad833c44690bf9d1d28eb35944e","ad1adee0aa644beebca99c06ab7725dd","739f538b6d0745a4a5ac09f4672f5fe9","39a47932419a4a4ab345df4da73066a4","a299408a661d4dc6bb79b80c7d1b2f96","8e4602d2f00e45f48d387c0dcd496dcd","9cefa96d7ef0480d8926f29963ee2293","5d057fc6c7f44331a7a24ae706340f82","502e69be638a4d5daeda9e8b1f3d0244","cca628fc2bce489b83e8ea15df892090","45d90d5ddce74017b7bfac2a60f496fb","8a0b191124b04fd5a4116ee80bbd0d33","939f86bed3df4d659e26af71e5befcd5","3815ce4fd631451ea80718e794ad5efb","a2f9ee5708704259940eda9ee33fc58b","b432caf2871640f1b88902bda5cdf56c","2f3794c3dde04d44811ed33ed52c7e32","fa1a9f3b9705428f8a7e7d8bda77c910","0445bd7b4863404d88c4d322d5d596c4","450850405da14b4990e364c07935d50b","8de921e6681d4dddbb0a557a7fba7f3e","cbb3a7b562d64b0892e43909d53f7652","5a60abe906e64cfabc511f9c13cbf549","e2346e4d09e3429d84a12aa71426db23","8ccc51b1af024527b2cc2ac31312c9ac","5c2c380239594cd29d055855e95b1db7"]},"id":"Zg1-3bPsWYqP","executionInfo":{"status":"ok","timestamp":1709014538394,"user_tz":-540,"elapsed":6224,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"c521b586-6326-42c5-bd23-f278c30af2f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b34848440a4b15aac63aab6b0e8aab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a299408a661d4dc6bb79b80c7d1b2f96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b432caf2871640f1b88902bda5cdf56c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","class SaveOnBestValidationLossCallback(TrainerCallback):\n","    def __init__(self):\n","        self.best_loss = float('inf')\n","\n","    def on_evaluate(self, args, state, control, **kwargs):\n","        # Check if the current validation loss is better (lower) than the best loss\n","        if state.log_history:\n","            current_loss = state.log_history[-1].get('eval_loss')\n","            if current_loss and current_loss < self.best_loss:\n","                self.best_loss = current_loss\n","                # Save the model\n","                model.save_pretrained(args.output_dir)\n","                tokenizer.save_pretrained(args.output_dir)\n","\n","# Add the callback to your trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    callbacks=[SaveOnBestValidationLossCallback()]\n",")"],"metadata":{"id":"opz-SdoQSO33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"JMZw0-cbXqdd"}},{"cell_type":"code","source":["trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(models_folder + \"gpt2-text-reps_custom_token_val\")"],"metadata":{"id":"fS1Do9IJXnpf","colab":{"base_uri":"https://localhost:8080/","height":925},"executionInfo":{"status":"error","timestamp":1709014880082,"user_tz":-540,"elapsed":338985,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"63863fab-913b-45e8-b065-4c79b0cf2f24"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2238' max='13500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2238/13500 05:36 < 28:14, 6.65 it/s, Epoch 16.57/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.794945</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.703922</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.663019</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.865800</td>\n","      <td>0.628382</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.865800</td>\n","      <td>0.605317</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.865800</td>\n","      <td>0.588280</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.865800</td>\n","      <td>0.578638</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.659400</td>\n","      <td>0.568519</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.659400</td>\n","      <td>0.562137</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.659400</td>\n","      <td>0.562696</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.659400</td>\n","      <td>0.559720</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.580000</td>\n","      <td>0.555546</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.580000</td>\n","      <td>0.553527</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.580000</td>\n","      <td>0.554853</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.517800</td>\n","      <td>0.559498</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.517800</td>\n","      <td>0.559021</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-c5d91a9d1c0a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"gpt2-text-reps_custom_token_val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1872\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 ):\n\u001b[1;32m   1876\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Assuming 'training_sequences.txt' is in the current directory\n","with open(\"training_sequences.txt\", \"r\") as file:\n","    total_examples = sum(1 for line in file)\n","\n","# Now calculate the epoch\n","batch_size = 4  # From your training configuration\n","checkpoint_step = 2000  # The step number in your checkpoint name\n","steps_per_epoch = total_examples / batch_size\n","estimated_epoch = checkpoint_step / steps_per_epoch\n","print(f\"Checkpoint was approximately at the end of epoch: {estimated_epoch:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2TjYuukR2Hi","executionInfo":{"status":"ok","timestamp":1709015789854,"user_tz":-540,"elapsed":425,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"b27e2770-01aa-433d-ba8a-f895291baf0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint was approximately at the end of epoch: 6.22\n"]}]},{"cell_type":"markdown","metadata":{"id":"USHfCOF5kMAu"},"source":["## Inference and decoding"]},{"cell_type":"code","source":["# Replace with your specific checkpoint path\n","checkpoint_path = models_folder + \"gpt2-text-reps_custom_token/checkpoint-2000\"  # xxxx should be replaced with the specific checkpoint number\n","\n","# Load the model from the checkpoint\n","model = GPT2LMHeadModel.from_pretrained(checkpoint_path)\n","\n","from transformers import PreTrainedTokenizerFast\n","\n","#tokenizer = PreTrainedTokenizerFast.from_pretrained(checkpoint_path)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jz-opyOqO7Sh","executionInfo":{"status":"ok","timestamp":1709015425722,"user_tz":-540,"elapsed":923,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"e6da824d-3bce-4b20-ca5c-2ff05698afd2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(1402, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=1402, bias=False)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lU5yxqBA3s2g"},"outputs":[],"source":["# Create a text generation pipeline using the GPU\n","generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4143,"status":"ok","timestamp":1709015436861,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"},"user_tz":-540},"id":"RFT71FM1oPUK","outputId":"184da470-846a-4da8-a23b-03e890ce622a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["# Define a starting prompt\n","prompt = \"C-7 F7\"  # Example starting sequence\n","\n","# The length you want for the generated part\n","desired_length = 400\n","\n","# Calculate the total length including the prompt\n","total_length = len(tokenizer.encode(prompt)) + desired_length\n","\n","# Generate text with the specified total length\n","generated_sequences = [sequence['generated_text'] for sequence in generator(prompt, max_length=total_length, num_return_sequences=3)]"]},{"cell_type":"code","source":["print(generated_sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2SfVFzxQm_q","executionInfo":{"status":"ok","timestamp":1709015464701,"user_tz":-540,"elapsed":417,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"}},"outputId":"6c7dd04e-5133-431e-d634-1c8bf44c6c89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['C-7 F7 | Bb- 7 Eb 7b9 | Ab ^ 7 | Ab- 7 Db 7 | F 9 | Bb- 7 | Eb7#11 D 9 | G- 7 C 7 | F 6 D7b9\\n A 7 | G- 7 C 7 | C 7 | G- 7 C 7 | A 7 | Bb- 7 Eb 7 | Ab ^ 7 | A- 7 Ab- 7 Db 7 | G- 7 C 7 | F- 7 Bb 7 | G- 7 D 7#9 | Db 7 C 7 | C- 7 F 7 | F- 7 Bb 7 | Eb ^ 7 | A- 7 Ab- 7 Db 7 | G- 7 C 7 | A 7 | Bb- 7 Eb 7 | Ab ^ 7 | A- 7 Ab- 7 Db 7 | G- 7 C 7 | A 7 | Bb- 7 Eb 7 | Ab ^ 7 | Ab- 7 Db 7 | F 9 | Bb- 7 | Eb7#11 D 9 | G- 7 C 7 | F6\\n F- 7 F# o 7 | G- 7 | G- 7 D 7#9 | A- 7 D 7 | F- 7 | Bb 7 | Eb ^ 7 E 7 | Eb ^ 7 | C^ 7 | F- 7 Bb 7 | Eb ^ 7 | E o 7 | F- 7 Db 7 | C- 7 B 7 | Bb- 7 | A h 7 D7b9 | G- 7 | F# o 7 | G- 7 D 7#9', 'C-7 F7 | Bb 6 Bb 7# 5 | Eb ^ 7 F7/ Bb | A 7 Ab 7#11 | Bb 6 D 7 | G- 7 C 7 | G- 7 C 7 | Bb 7 Eb- 7 | D 7 G7b9 | C- 7 F 7 | Bb 6 F7\\n Bb 6 | D-7/ C | G / D | G / D | G / D | E 7sus Bb / D | A- 7 | D 7sus | Bb 7#9 | Bb 6 | D-7/ C | G / D | G / D | G / D | G / D | A- 7 | D 7sus | Bb 7#9 | Bb 6 | G- 7 F# 7b13 | E 7sus D 7 | G- 7 F# 7b13 G- 7 | Bb 6 Ab 7 | Bb 6 C 7 | F 6 E- 7 A 7 | D- 7 G 7 | C^ 7 | D- 7 G 7 | C^ 7 | C 7 | Bb 6 Bb 7# 5 | Eb ^ 7 C-7/ Bb | A 7 Ab 7#11 | Bb 6 D 7 | G- 7 C 7 | G- 7 C 7 | Bb 7 Eb- 7 | D 7 G7b9 | C- 7 F 7 | Bb 6 F7\\n Bb ^ 7 G 7 | C- 7 F 7 | D- 7 G 7 | C- 7 F 7 | D- 7 G 7 | C- 7 F 7 | Bb Bb', 'C-7 F7 | Bb 6 G- 7 | C- 7 F 7 | Bb 6 G- 7 | C- 7 F 7 | Bb 6 G- 7 | C- 7 F 7 | Bb 6 G- 7 | C- 7 F 7 | Bb 6 G- 7 | C-7\\n E- 7 | A- 7 | D- 7 | G 7 | C^ 7 | C^ 7 | Bb o 7 | F /A Bb o 7 | D- 7 | G 7 | C^ 7 | C 6 9 | G- 7 C 7 | F^ 7 | Bb A 7 | D- 7 G7\\n C#- 7 F# 7 | B ^ 7 G- | F#- 7 B 7 | E ^ 7 C ^7/ B | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 B 7 | E ^ 7 A 7 | D 7 | D- 7']\n"]}]},{"cell_type":"code","source":["rearranged_sequences = []\n","\n","for sequence in generated_sequences:\n","    # Remove all existing spaces\n","    sequence_no_spaces = sequence.replace(\" \", \"\")\n","\n","    new_sequence = ''\n","    for char in sequence_no_spaces:\n","        new_sequence += char\n","        if char in ['E', 'F']:\n","            new_sequence += ' '\n","\n","    # Strip trailing space and add to list\n","    rearranged_sequences.append(new_sequence.strip())\n","\n","# rearranged_sequences now contains the modified sequences\n","\n","# Process and transpose the generated sequences\n","all_transposed_sequences, all_final_sequences = process_and_transpose_sequences(rearranged_sequences, mapped_results)\n","\n","# Print the final transposed chord stream for each generated sequence\n","for sequence_index, transposed_chords in enumerate(all_transposed_sequences):\n","    print(f\"Transposed Sequence {sequence_index + 1}:\")\n","    for first_chord, second_chord in transposed_chords:\n","        print(f\"{first_chord} {second_chord}\")\n","    print()  # Print a new line for separation between sequences\n","\n","# Print the final sequence as a stream of first chords with bar tokens\n","for sequence_index, final_sequence in enumerate(all_final_sequences):\n","    print(f\"Final Chord Stream {sequence_index + 1}: {' '.join(final_sequence)}\")\n","    print()  # Print a new line for separation between sequences"],"metadata":{"id":"K2WEdylTOGfN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eL0GgR0qkSh9"},"source":["# Else"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":482,"status":"ok","timestamp":1707901749265,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"},"user_tz":-540},"id":"akkY0dmB4HbY","outputId":"3f4ac43b-1e3d-4f1f-c2cf-af3fbff4cccb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Formatted Sequence 1: C-7.|F7.|C7.|A7.|D7.|D-7.|G7.|G-7.|C7.|C-7.|F7.|Bb^7.|F-7.|Bbh7.|Ebh7.|Ab7b9.|Db-7.|Gb7.|Ab-7.|Dbh7.|Gb7b9.|B-7.|E-7.|Dh7.|D-7.|G7.|A-7.|G-7.|F-7.|Bb7.|C-7.|Bb-7.|Eb7.|F-7.|Eb-7.|Db-7.|Gb7.|Db7.|Bb7.|Eb7.|Eb-7.|Ab7.|Db^7.|Ab-7.|\n","Formatted Sequence 2: C-7.|F7.|Bb-7.|Bb-7.|Eb7.|F-7.|F-7.|Bb7.|C-7.|Co7.|C^7#5.|E^7.|Gb^7.|Eb7.|F^7.|A-7.|D7.|G^7.|G^7.|B-7.|E7.|A^7.|A^7.|Db-7.|Gb7.|Ab-7.|E7.|A-7.|A-7.|D7.|E-7.|E-7.|A7.|B^7.|Eb-7.|Ab7.|Bb-7.|Ab7.|Gb^7.|Gb^7.|Bb-7.|\n","Formatted Sequence 3: C-7.|F7.|F7.|Bb7.|Bb7.|Eb7.|Eb7.|Ab7.|Ab7.|Db7.|Db7.|Gb7.|Ab-7.|Ab9#5.|Db^7.|C-7.|F7.|F7.|Bb7.|Bb7.|Eb7.|Ab7.|Ab7.|Db7.|Db7.|Gb7.|B7.|B7.|E7.|E7.|A7.|A7.|D7.|D7.|G7.|G7.|C7.|F7.|G^7.|G^7.|Co7.|Co7.|Db-7.|B-7.|A-7.|B-7.|E7.|Gbh7.|B7b9.|E-7.|\n"]}],"source":["formatted_chord_sequences = []\n","\n","for transposed_chords in all_transposed_sequences:\n","    # Join the first chord of each pair with the specified format\n","    formatted_sequence = \"|\".join([f\"{chord[0]}.\" for chord in transposed_chords]) + \"|\"\n","    formatted_chord_sequences.append(formatted_sequence)\n","\n","# Print the formatted chord sequences\n","for sequence_index, sequence in enumerate(formatted_chord_sequences):\n","    print(f\"Formatted Sequence {sequence_index + 1}: {sequence}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":1264,"status":"error","timestamp":1709017872429,"user":{"displayName":"Chanhoo Kum","userId":"09646319741024999619"},"user_tz":-540},"id":"bNSoDP-ElELA","outputId":"24bf776c-4b02-47dc-e0e8-d1c1da085d43"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'chord_sequences.txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-f52c78c7aae9>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read and tokenize each line in the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chord_sequences.txt'"]}],"source":["import matplotlib.pyplot as plt\n","\n","# Path to your file\n","file_path = \"chord_sequences.txt\"\n","\n","# Initialize a list to store the lengths\n","sequence_lengths = []\n","\n","# Read and tokenize each line in the file\n","with open(file_path, 'r', encoding='utf-8') as file:\n","    for line in file:\n","        tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n","        sequence_lengths.append(len(tokens))\n","\n","# You can now analyze the sequence_lengths list to determine the optimal block size\n","print(\"Token lengths of sequences:\", sequence_lengths)\n","\n","# Example analysis: Find the maximum length\n","max_length = max(sequence_lengths)\n","print(\"Maximum token length:\", max_length)\n","\n","# Example analysis: Find the average length\n","average_length = sum(sequence_lengths) / len(sequence_lengths)\n","print(\"Average token length:\", average_length)\n","\n","# Plotting a histogram of the sequence lengths\n","plt.figure(figsize=(10, 6))\n","plt.hist(sequence_lengths, bins=20, edgecolor='black')\n","plt.title(\"Histogram of Token Lengths of Sequences\")\n","plt.xlabel(\"Token Length\")\n","plt.ylabel(\"Frequency\")\n","plt.grid(True)\n","plt.show()\n","\n","# Optional: Calculating the variance\n","variance = sum((x - sum(sequence_lengths) / len(sequence_lengths)) ** 2 for x in sequence_lengths) / len(sequence_lengths)\n","print(f\"Variance of Token Lengths: {variance}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMzhi+zjzR6J0H55X91se9A"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"34b34848440a4b15aac63aab6b0e8aab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_366a2eed12964e68b42afa9670b62a65","IPY_MODEL_056cbf7417e640f4bcded50d0a217c03","IPY_MODEL_e3c61bca26484305baffe5e0e15fa7a5"],"layout":"IPY_MODEL_6fba82c7940d4e8ea9f7512553b82858"}},"366a2eed12964e68b42afa9670b62a65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32c4e9adcab14b25b0ef3fa5ca7fb87b","placeholder":"​","style":"IPY_MODEL_ff901cacea74432296ec0d8ca33ec64e","value":"config.json: 100%"}},"056cbf7417e640f4bcded50d0a217c03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a015ad833c44690bf9d1d28eb35944e","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad1adee0aa644beebca99c06ab7725dd","value":665}},"e3c61bca26484305baffe5e0e15fa7a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_739f538b6d0745a4a5ac09f4672f5fe9","placeholder":"​","style":"IPY_MODEL_39a47932419a4a4ab345df4da73066a4","value":" 665/665 [00:00&lt;00:00, 53.5kB/s]"}},"6fba82c7940d4e8ea9f7512553b82858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c4e9adcab14b25b0ef3fa5ca7fb87b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff901cacea74432296ec0d8ca33ec64e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a015ad833c44690bf9d1d28eb35944e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad1adee0aa644beebca99c06ab7725dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"739f538b6d0745a4a5ac09f4672f5fe9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a47932419a4a4ab345df4da73066a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a299408a661d4dc6bb79b80c7d1b2f96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e4602d2f00e45f48d387c0dcd496dcd","IPY_MODEL_9cefa96d7ef0480d8926f29963ee2293","IPY_MODEL_5d057fc6c7f44331a7a24ae706340f82"],"layout":"IPY_MODEL_502e69be638a4d5daeda9e8b1f3d0244"}},"8e4602d2f00e45f48d387c0dcd496dcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cca628fc2bce489b83e8ea15df892090","placeholder":"​","style":"IPY_MODEL_45d90d5ddce74017b7bfac2a60f496fb","value":"model.safetensors: 100%"}},"9cefa96d7ef0480d8926f29963ee2293":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a0b191124b04fd5a4116ee80bbd0d33","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_939f86bed3df4d659e26af71e5befcd5","value":548105171}},"5d057fc6c7f44331a7a24ae706340f82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3815ce4fd631451ea80718e794ad5efb","placeholder":"​","style":"IPY_MODEL_a2f9ee5708704259940eda9ee33fc58b","value":" 548M/548M [00:01&lt;00:00, 394MB/s]"}},"502e69be638a4d5daeda9e8b1f3d0244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cca628fc2bce489b83e8ea15df892090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d90d5ddce74017b7bfac2a60f496fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a0b191124b04fd5a4116ee80bbd0d33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"939f86bed3df4d659e26af71e5befcd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3815ce4fd631451ea80718e794ad5efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2f9ee5708704259940eda9ee33fc58b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b432caf2871640f1b88902bda5cdf56c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f3794c3dde04d44811ed33ed52c7e32","IPY_MODEL_fa1a9f3b9705428f8a7e7d8bda77c910","IPY_MODEL_0445bd7b4863404d88c4d322d5d596c4"],"layout":"IPY_MODEL_450850405da14b4990e364c07935d50b"}},"2f3794c3dde04d44811ed33ed52c7e32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8de921e6681d4dddbb0a557a7fba7f3e","placeholder":"​","style":"IPY_MODEL_cbb3a7b562d64b0892e43909d53f7652","value":"generation_config.json: 100%"}},"fa1a9f3b9705428f8a7e7d8bda77c910":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a60abe906e64cfabc511f9c13cbf549","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2346e4d09e3429d84a12aa71426db23","value":124}},"0445bd7b4863404d88c4d322d5d596c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ccc51b1af024527b2cc2ac31312c9ac","placeholder":"​","style":"IPY_MODEL_5c2c380239594cd29d055855e95b1db7","value":" 124/124 [00:00&lt;00:00, 7.25kB/s]"}},"450850405da14b4990e364c07935d50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8de921e6681d4dddbb0a557a7fba7f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbb3a7b562d64b0892e43909d53f7652":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a60abe906e64cfabc511f9c13cbf549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2346e4d09e3429d84a12aa71426db23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ccc51b1af024527b2cc2ac31312c9ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c2c380239594cd29d055855e95b1db7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}